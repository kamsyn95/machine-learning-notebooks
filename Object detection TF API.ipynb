{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object detection TF API.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Tensorflow 2 Object Detection: Train model\n","\n"],"metadata":{"id":"GaTTQ6iSRVZx"}},{"cell_type":"markdown","source":["This notebook walks you through training a custom object detection model using the Tensorflow Object Detection API and Tensorflow 2.\n","\n","The notebook is split into the following parts:\n","* Install the Tensorflow Object Detection API\n","* Prepare data for use with the OD API\n","* Write custom training configuration\n","* Train detector\n","* Export model inference graph\n","* Test trained model"],"metadata":{"id":"9Yr4xvQ4VcW_"}},{"cell_type":"markdown","source":["## Installation\n","\n","Installing the Tensorflow Object Detection API became a lot easier with the relase of Tensorflow 2. The following few cells are all that is needed in order to install the OD API."],"metadata":{"id":"KNT9cI_ZSCla"}},{"cell_type":"code","execution_count":null,"source":["# !pip install tensorflow==\"2.6.0\"\n","\n","# Tensorflow 2.7.0 already installed\n","!pip list"],"outputs":[],"metadata":{"id":"fTBYWlnKSD78"}},{"cell_type":"code","execution_count":null,"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 3130, done.\u001b[K\n","remote: Counting objects: 100% (3130/3130), done.\u001b[K\n","remote: Compressing objects: 100% (2664/2664), done.\u001b[K\n","remote: Total 3130 (delta 787), reused 1312 (delta 422), pack-reused 0\u001b[K\n","Receiving objects: 100% (3130/3130), 33.40 MiB | 25.65 MiB/s, done.\n","Resolving deltas: 100% (787/787), done.\n"]}],"metadata":{"id":"Kpha2-F_SGBj","executionInfo":{"status":"ok","timestamp":1642434228753,"user_tz":-60,"elapsed":3975,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4a34db9-a2bc-4530-8b13-6d40b8f5690a"}},{"cell_type":"code","execution_count":null,"source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/models/research\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.35.0-cp37-cp37m-manylinux2010_x86_64.whl (9.9 MB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.26)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n","Collecting tensorflow_io\n","  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Collecting tensorflow-text>=2.7.0\n","  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.6)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.23.1)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.5-cp37-cp37m-manylinux_2_24_x86_64.whl (247 kB)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.19.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.10)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.5.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1684828 sha256=7a67a69f8a29e9367736c5ae7cb96cc17455d627b5b21a8af75add5aaa4dfaa4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kv6j1o87/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py): started\n","  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=15a51bb3fba8b0aff70c59bb1831e39a68731be69e90f3e0729b3e30d326b2f9\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=77050dcd43030af4892ee068428c371d6395672e9856b02ede06a6af1e1effb3\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=e4d6c7ad6028af938d8bece035ae6f585c705ff072aee40efa16cfee79bb9d4e\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py): started\n","  Building wheel for seqeval (setup.py): finished with status 'done'\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=20d46bf407ec54a46d1fa402aec50c71293cb0a23c836131e74bc09032437d1c\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.0.1\n","    Uninstalling pymongo-4.0.1:\n","      Successfully uninstalled pymongo-4.0.1\n","Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.5 portalocker-2.3.2 proto-plus-1.19.8 protobuf-3.19.3 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-6.0 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"]},{"output_type":"stream","name":"stderr","text":["  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"]}],"metadata":{"id":"rmr2UdV_SHuc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"715925ab-2529-4c31-d5f5-9238ec488529","executionInfo":{"status":"ok","timestamp":1642434268262,"user_tz":-60,"elapsed":39512,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["#run model builder test\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"],"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.12: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-01-17 15:44:35.485712: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0117 15:44:35.947600 139661452699520 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.67s\n","I0117 15:44:36.283091 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.67s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.65s\n","I0117 15:44:36.937606 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.65s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","I0117 15:44:37.281121 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n","I0117 15:44:37.598162 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s\n","I0117 15:44:39.849016 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0117 15:44:39.850282 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0117 15:44:39.879155 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0117 15:44:39.898254 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0117 15:44:39.917106 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","I0117 15:44:40.041698 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n","I0117 15:44:40.173608 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","I0117 15:44:40.301134 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n","I0117 15:44:40.433347 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n","I0117 15:44:40.554022 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0117 15:44:40.589132 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0117 15:44:40.801711 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0117 15:44:40.801909 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0117 15:44:40.802008 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0117 15:44:40.804518 139661452699520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:44:40.823753 139661452699520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:44:40.823885 139661452699520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:44:40.901078 139661452699520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:44:40.901273 139661452699520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:44:41.086045 139661452699520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:44:41.086255 139661452699520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 15:44:41.283782 139661452699520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 15:44:41.284076 139661452699520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 15:44:41.759876 139661452699520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 15:44:41.760075 139661452699520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 15:44:42.034119 139661452699520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 15:44:42.034311 139661452699520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 15:44:42.408387 139661452699520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 15:44:42.408602 139661452699520 efficientnet_model.py:147] round_filter input=320 output=320\n","I0117 15:44:42.497940 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0117 15:44:42.533787 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0117 15:44:42.595477 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0117 15:44:42.595653 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0117 15:44:42.595782 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0117 15:44:42.597714 139661452699520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:44:42.615331 139661452699520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:44:42.615508 139661452699520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:44:42.764651 139661452699520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:44:42.764859 139661452699520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:44:43.054059 139661452699520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:44:43.054263 139661452699520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 15:44:43.348340 139661452699520 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 15:44:43.348558 139661452699520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 15:44:43.741589 139661452699520 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 15:44:43.741840 139661452699520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 15:44:44.126300 139661452699520 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 15:44:44.126504 139661452699520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 15:44:44.605854 139661452699520 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 15:44:44.606108 139661452699520 efficientnet_model.py:147] round_filter input=320 output=320\n","I0117 15:44:44.782893 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0117 15:44:44.817400 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0117 15:44:44.896490 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0117 15:44:44.896642 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0117 15:44:44.896741 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0117 15:44:44.898607 139661452699520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:44:44.916374 139661452699520 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:44:44.916492 139661452699520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:44:45.073508 139661452699520 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:44:45.073762 139661452699520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:44:45.356787 139661452699520 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:44:45.357011 139661452699520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0117 15:44:45.632022 139661452699520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0117 15:44:45.632212 139661452699520 efficientnet_model.py:147] round_filter input=80 output=88\n","I0117 15:44:46.007483 139661452699520 efficientnet_model.py:147] round_filter input=80 output=88\n","I0117 15:44:46.007689 139661452699520 efficientnet_model.py:147] round_filter input=112 output=120\n","I0117 15:44:46.398579 139661452699520 efficientnet_model.py:147] round_filter input=112 output=120\n","I0117 15:44:46.398809 139661452699520 efficientnet_model.py:147] round_filter input=192 output=208\n","I0117 15:44:47.081464 139661452699520 efficientnet_model.py:147] round_filter input=192 output=208\n","I0117 15:44:47.081717 139661452699520 efficientnet_model.py:147] round_filter input=320 output=352\n","I0117 15:44:47.267269 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0117 15:44:47.311661 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0117 15:44:47.393845 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0117 15:44:47.394089 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0117 15:44:47.394202 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0117 15:44:47.396462 139661452699520 efficientnet_model.py:147] round_filter input=32 output=40\n","I0117 15:44:47.415281 139661452699520 efficientnet_model.py:147] round_filter input=32 output=40\n","I0117 15:44:47.415400 139661452699520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0117 15:44:47.568240 139661452699520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0117 15:44:47.568470 139661452699520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0117 15:44:47.852039 139661452699520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0117 15:44:47.852270 139661452699520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0117 15:44:48.133173 139661452699520 efficientnet_model.py:147] round_filter input=40 output=48\n","I0117 15:44:48.133382 139661452699520 efficientnet_model.py:147] round_filter input=80 output=96\n","I0117 15:44:48.600413 139661452699520 efficientnet_model.py:147] round_filter input=80 output=96\n","I0117 15:44:48.600641 139661452699520 efficientnet_model.py:147] round_filter input=112 output=136\n","I0117 15:44:49.056019 139661452699520 efficientnet_model.py:147] round_filter input=112 output=136\n","I0117 15:44:49.056225 139661452699520 efficientnet_model.py:147] round_filter input=192 output=232\n","I0117 15:44:49.625268 139661452699520 efficientnet_model.py:147] round_filter input=192 output=232\n","I0117 15:44:49.625484 139661452699520 efficientnet_model.py:147] round_filter input=320 output=384\n","I0117 15:44:49.812579 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0117 15:44:49.848386 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0117 15:44:49.936108 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0117 15:44:49.936305 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0117 15:44:49.936403 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0117 15:44:49.938653 139661452699520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0117 15:44:49.958551 139661452699520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0117 15:44:49.958679 139661452699520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0117 15:44:50.112220 139661452699520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0117 15:44:50.112525 139661452699520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0117 15:44:50.502231 139661452699520 efficientnet_model.py:147] round_filter input=24 output=32\n","I0117 15:44:50.502487 139661452699520 efficientnet_model.py:147] round_filter input=40 output=56\n","I0117 15:44:50.873102 139661452699520 efficientnet_model.py:147] round_filter input=40 output=56\n","I0117 15:44:50.873333 139661452699520 efficientnet_model.py:147] round_filter input=80 output=112\n","I0117 15:44:51.432095 139661452699520 efficientnet_model.py:147] round_filter input=80 output=112\n","I0117 15:44:51.432325 139661452699520 efficientnet_model.py:147] round_filter input=112 output=160\n","I0117 15:44:51.975725 139661452699520 efficientnet_model.py:147] round_filter input=112 output=160\n","I0117 15:44:51.976019 139661452699520 efficientnet_model.py:147] round_filter input=192 output=272\n","I0117 15:44:52.719499 139661452699520 efficientnet_model.py:147] round_filter input=192 output=272\n","I0117 15:44:52.719695 139661452699520 efficientnet_model.py:147] round_filter input=320 output=448\n","I0117 15:44:53.188416 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0117 15:44:53.223144 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0117 15:44:53.319600 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0117 15:44:53.319901 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0117 15:44:53.320116 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0117 15:44:53.322355 139661452699520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0117 15:44:53.342143 139661452699520 efficientnet_model.py:147] round_filter input=32 output=48\n","I0117 15:44:53.342280 139661452699520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0117 15:44:53.580922 139661452699520 efficientnet_model.py:147] round_filter input=16 output=24\n","I0117 15:44:53.581223 139661452699520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0117 15:44:54.044480 139661452699520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0117 15:44:54.044733 139661452699520 efficientnet_model.py:147] round_filter input=40 output=64\n","I0117 15:44:54.515678 139661452699520 efficientnet_model.py:147] round_filter input=40 output=64\n","I0117 15:44:54.515934 139661452699520 efficientnet_model.py:147] round_filter input=80 output=128\n","I0117 15:44:55.159373 139661452699520 efficientnet_model.py:147] round_filter input=80 output=128\n","I0117 15:44:55.159581 139661452699520 efficientnet_model.py:147] round_filter input=112 output=176\n","I0117 15:44:55.845597 139661452699520 efficientnet_model.py:147] round_filter input=112 output=176\n","I0117 15:44:55.845830 139661452699520 efficientnet_model.py:147] round_filter input=192 output=304\n","I0117 15:44:56.683777 139661452699520 efficientnet_model.py:147] round_filter input=192 output=304\n","I0117 15:44:56.684036 139661452699520 efficientnet_model.py:147] round_filter input=320 output=512\n","I0117 15:44:56.969148 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0117 15:44:57.007881 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0117 15:44:57.113644 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0117 15:44:57.113869 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0117 15:44:57.113967 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0117 15:44:57.116092 139661452699520 efficientnet_model.py:147] round_filter input=32 output=56\n","I0117 15:44:57.136446 139661452699520 efficientnet_model.py:147] round_filter input=32 output=56\n","I0117 15:44:57.136658 139661452699520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0117 15:44:57.371534 139661452699520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0117 15:44:57.371820 139661452699520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0117 15:44:57.961673 139661452699520 efficientnet_model.py:147] round_filter input=24 output=40\n","I0117 15:44:57.961930 139661452699520 efficientnet_model.py:147] round_filter input=40 output=72\n","I0117 15:44:58.546236 139661452699520 efficientnet_model.py:147] round_filter input=40 output=72\n","I0117 15:44:58.546471 139661452699520 efficientnet_model.py:147] round_filter input=80 output=144\n","I0117 15:44:59.315806 139661452699520 efficientnet_model.py:147] round_filter input=80 output=144\n","I0117 15:44:59.316050 139661452699520 efficientnet_model.py:147] round_filter input=112 output=200\n","I0117 15:45:00.331504 139661452699520 efficientnet_model.py:147] round_filter input=112 output=200\n","I0117 15:45:00.331706 139661452699520 efficientnet_model.py:147] round_filter input=192 output=344\n","I0117 15:45:01.361202 139661452699520 efficientnet_model.py:147] round_filter input=192 output=344\n","I0117 15:45:01.361452 139661452699520 efficientnet_model.py:147] round_filter input=320 output=576\n","I0117 15:45:01.666504 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0117 15:45:01.703408 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0117 15:45:01.826744 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0117 15:45:01.827059 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0117 15:45:01.827187 139661452699520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0117 15:45:01.829404 139661452699520 efficientnet_model.py:147] round_filter input=32 output=64\n","I0117 15:45:01.849173 139661452699520 efficientnet_model.py:147] round_filter input=32 output=64\n","I0117 15:45:01.849350 139661452699520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0117 15:45:02.160197 139661452699520 efficientnet_model.py:147] round_filter input=16 output=32\n","I0117 15:45:02.160430 139661452699520 efficientnet_model.py:147] round_filter input=24 output=48\n","I0117 15:45:02.837680 139661452699520 efficientnet_model.py:147] round_filter input=24 output=48\n","I0117 15:45:02.838014 139661452699520 efficientnet_model.py:147] round_filter input=40 output=80\n","I0117 15:45:03.506205 139661452699520 efficientnet_model.py:147] round_filter input=40 output=80\n","I0117 15:45:03.506411 139661452699520 efficientnet_model.py:147] round_filter input=80 output=160\n","I0117 15:45:04.433616 139661452699520 efficientnet_model.py:147] round_filter input=80 output=160\n","I0117 15:45:04.433881 139661452699520 efficientnet_model.py:147] round_filter input=112 output=224\n","I0117 15:45:05.351632 139661452699520 efficientnet_model.py:147] round_filter input=112 output=224\n","I0117 15:45:05.351863 139661452699520 efficientnet_model.py:147] round_filter input=192 output=384\n","I0117 15:45:06.886738 139661452699520 efficientnet_model.py:147] round_filter input=192 output=384\n","I0117 15:45:06.887017 139661452699520 efficientnet_model.py:147] round_filter input=320 output=640\n","I0117 15:45:07.278270 139661452699520 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0117 15:45:07.313656 139661452699520 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.88s\n","I0117 15:45:07.468075 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.88s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0117 15:45:07.475732 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0117 15:45:07.477704 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0117 15:45:07.478286 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0117 15:45:07.480101 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0117 15:45:07.481847 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0117 15:45:07.482366 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0117 15:45:07.483473 139661452699520 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 34.866s\n","\n","OK (skipped=1)\n"]}],"metadata":{"id":"XzXxTBXHSNqA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"688b8979-1c85-4bb1-a62a-4f2ba565be6e","executionInfo":{"status":"ok","timestamp":1642434309012,"user_tz":-60,"elapsed":40755,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"markdown","source":["## Prepare data\n","\n","To train a robust model, you need a lot of pictures that vary greatly from each other. You can either take the pictures yourself or you can download them from the internet.\n","\n","After collecting the images you need to label them. For this I recommend using [LabelImg](https://github.com/tzutalin/labelImg) - an free, open source graphical image annotation tool.\n","\n","After labeling the images, split the data into a training and testing part and convert the xml label files to csv using the [xml_to_csv.py](https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/xml_to_csv.py) script.\n","\n","I uploaded my Microcontroller Detection data-set on Kaggle. The below four cells are used to download and extract the data-set."],"metadata":{"id":"Iz1sd2reSTxg"}},{"cell_type":"code","execution_count":null,"source":["# Install Kaggle API\n","!pip install -q kaggle\n","# !pip install -q kaggle-cli"],"outputs":[],"metadata":{"id":"N8XSaOzhSX-n"}},{"cell_type":"code","execution_count":null,"source":["# # only for google colab\n","# import os\n","# os.environ['KAGGLE_USERNAME'] = \"<username>\" \n","# os.environ['KAGGLE_KEY'] = \"<key>\""],"outputs":[],"metadata":{"id":"SQqz-fsJbiQ0"}},{"cell_type":"code","source":["# Choose the kaggle.json file that you downloaded\n","from google.colab import files \n","files.upload()"],"metadata":{"id":"KDGNzzJPyfk4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","mkdir ~/.kaggle\n","cp kaggle.json ~/.kaggle/\n","chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"JSm5JOyTyuIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"source":["!kaggle datasets download -d tannergi/microcontroller-detection --unzip"],"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading microcontroller-detection.zip to /content\n","\r  0% 0.00/8.34M [00:00<?, ?B/s]\n","\r100% 8.34M/8.34M [00:00<00:00, 76.2MB/s]\n"]}],"metadata":{"id":"cozgoQPEbo-k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"13d33642-f044-4132-d7a9-09a48d569472","executionInfo":{"status":"ok","timestamp":1642434338804,"user_tz":-60,"elapsed":1268,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["!mv \"Microcontroller Detection\" microcontroller-detection"],"outputs":[],"metadata":{"id":"LbRcqKh5b-j7"}},{"cell_type":"code","execution_count":null,"source":["!wget https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/generate_tfrecord.py"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-17 15:45:38--  https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/generate_tfrecord.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3470 (3.4K) [text/plain]\n","Saving to: ‘generate_tfrecord.py’\n","\n","\rgenerate_tfrecord.p   0%[                    ]       0  --.-KB/s               \rgenerate_tfrecord.p 100%[===================>]   3.39K  --.-KB/s    in 0s      \n","\n","2022-01-17 15:45:39 (47.7 MB/s) - ‘generate_tfrecord.py’ saved [3470/3470]\n","\n"]}],"metadata":{"id":"3KHDdTY_cm5G","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc14c1b8-9f94-45b1-c03a-b68d6b2d742f","executionInfo":{"status":"ok","timestamp":1642434339020,"user_tz":-60,"elapsed":219,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["!wget https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/training/labelmap.pbtxt"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-17 15:45:39--  https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/training/labelmap.pbtxt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 177 [text/plain]\n","Saving to: ‘labelmap.pbtxt’\n","\n","\rlabelmap.pbtxt        0%[                    ]       0  --.-KB/s               \rlabelmap.pbtxt      100%[===================>]     177  --.-KB/s    in 0s      \n","\n","2022-01-17 15:45:39 (4.91 MB/s) - ‘labelmap.pbtxt’ saved [177/177]\n","\n"]}],"metadata":{"id":"5IRZfTu6di4R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1dc1323b-5261-441e-c6f3-03862b3c10ea","executionInfo":{"status":"ok","timestamp":1642434339414,"user_tz":-60,"elapsed":396,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["!python generate_tfrecord.py --csv_input=microcontroller-detection/train_labels.csv --image_dir=microcontroller-detection/train --output_path=train.record\n","!python generate_tfrecord.py --csv_input=microcontroller-detection/test_labels.csv --image_dir=microcontroller-detection/test --output_path=test.record"],"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecords: /content/train.record\n","Successfully created the TFRecords: /content/test.record\n"]}],"metadata":{"id":"hs4KdOs7coyX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"360069d3-e066-475f-8483-632f7e57eded","executionInfo":{"status":"ok","timestamp":1642434347424,"user_tz":-60,"elapsed":8012,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["train_record_path = '/content/train.record'\n","test_record_path = '/content/test.record'\n","labelmap_path = '/content/labelmap.pbtxt'"],"outputs":[],"metadata":{"id":"Z_W_8L24c4Sk"}},{"cell_type":"markdown","source":["## Configuring training\n","\n","Now that the data is ready it's time to create a training configuration. The OD API supports lots of models, each with its own config file. In this notebook I'm making use of EfficientDet, but you can replace it with any model available in the [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."],"metadata":{"id":"SK79i98YSY8a"}},{"cell_type":"code","execution_count":null,"source":["batch_size = 16\n","num_steps = 8000\n","num_eval_steps = 1000"],"outputs":[],"metadata":{"id":"Axko9Jd0hEI3"}},{"cell_type":"code","execution_count":null,"source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-17 15:45:58--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.136.128, 2607:f8b0:4001:c34::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.136.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30736482 (29M) [application/x-tar]\n","Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz’\n","\n","efficientdet_d0_coc 100%[===================>]  29.31M  --.-KB/s    in 0.1s    \n","\n","2022-01-17 15:45:58 (201 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz’ saved [30736482/30736482]\n","\n"]}],"metadata":{"id":"8RNI68K_dyzX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3900c3a4-7374-4506-c4c5-e70946412395","executionInfo":{"status":"ok","timestamp":1642434359310,"user_tz":-60,"elapsed":1213,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["fine_tune_checkpoint = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'"],"outputs":[],"metadata":{"id":"HKENdH3TfhGb"}},{"cell_type":"code","execution_count":null,"source":["!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-17 15:45:59--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4630 (4.5K) [text/plain]\n","Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’\n","\n","\r          ssd_effic   0%[                    ]       0  --.-KB/s               \rssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n","\n","2022-01-17 15:45:59 (48.4 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config’ saved [4630/4630]\n","\n"]}],"metadata":{"id":"qzQ84qIQelJB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7812a549-4797-4e21-e22a-92897dd5e478","executionInfo":{"status":"ok","timestamp":1642434359771,"user_tz":-60,"elapsed":464,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","source":["base_config_path = 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'"],"metadata":{"id":"x3Wpg0jHFYnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"source":["# edit configuration file (from https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD)\n","\n","import re\n","\n","with open(base_config_path) as f:\n","    config = f.read()\n","\n","with open('model_config.config', 'w') as f:\n","  \n","  # Set labelmap path\n","  config = re.sub('label_map_path: \".*?\"', \n","             'label_map_path: \"{}\"'.format(labelmap_path), config)\n","  \n","  # Set fine_tune_checkpoint path\n","  config = re.sub('fine_tune_checkpoint: \".*?\"',\n","                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n","  \n","  # Set train tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n","                  'input_path: \"{}\"'.format(train_record_path), config)\n","  \n","  # Set test tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n","                  'input_path: \"{}\"'.format(test_record_path), config)\n","  \n","  # Set number of classes.\n","  config = re.sub('num_classes: [0-9]+',\n","                  'num_classes: {}'.format(4), config)\n","  \n","  # Set batch size\n","  config = re.sub('batch_size: [0-9]+',\n","                  'batch_size: {}'.format(batch_size), config)\n","  \n","  # Set training steps\n","  config = re.sub('num_steps: [0-9]+',\n","                  'num_steps: {}'.format(num_steps), config)\n","  \n","  # Set fine-tune checkpoint type to detection\n","  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n","             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n","  \n","  f.write(config)"],"outputs":[],"metadata":{"id":"m3ehVTRgesxS"}},{"cell_type":"code","execution_count":null,"source":["%cat model_config.config"],"outputs":[{"output_type":"stream","name":"stdout","text":[" # SSD with EfficientNet-b0 + BiFPN feature extractor,\n","# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n","# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n","# See Lin et al, https://arxiv.org/abs/1708.02002\n","# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n","#\n","# Train on TPU-8\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 4\n","    add_background_class: false\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [1.0, 2.0, 0.5]\n","        scales_per_octave: 3\n","      }\n","    }\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 512\n","        max_dimension: 512\n","        pad_to_max_dimension: true\n","        }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        depth: 64\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          force_use_bias: true\n","          activation: SWISH\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true\n","            decay: 0.99\n","            epsilon: 0.001\n","          }\n","        }\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        use_depthwise: true\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_efficientnet-b0_bifpn_keras'\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","      conv_hyperparams {\n","        force_use_bias: true\n","        activation: SWISH\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          decay: 0.99,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.25\n","          gamma: 1.5\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint: \"efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 16\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  use_bfloat16: true\n","  num_steps: 8000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_scale_crop_and_pad_to_square {\n","      output_size: 512\n","      scale_min: 0.1\n","      scale_max: 2.0\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 8e-2\n","          total_steps: 300000\n","          warmup_learning_rate: .001\n","          warmup_steps: 2500\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/labelmap.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 16;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/labelmap.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/test.record\"\n","  }\n","}\n"]}],"metadata":{"id":"SmtrS5dihpS_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"80ba2a9e-ff4c-4cdf-fde6-9e9cd06a85e4","executionInfo":{"status":"ok","timestamp":1642434359772,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["model_dir = 'training/'\n","pipeline_config_path = 'model_config.config'"],"outputs":[],"metadata":{"id":"eRTBSsYthwxG"}},{"cell_type":"markdown","source":["## Train detector"],"metadata":{"id":"Tv0sbQlciKWA"}},{"cell_type":"code","source":["# Fixing the problem:\n","# ImportError: cannot import name '_registerMatType' from 'cv2.cv2' \n","# (/usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so)\n","\n","!pip uninstall opencv-python-headless \n","!pip install opencv-python-headless==4.1.2.30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmZhZmOi67RZ","executionInfo":{"status":"ok","timestamp":1642434389622,"user_tz":-60,"elapsed":14044,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}},"outputId":"33273b85-d399-4c67-80e2-6807ae73301d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: opencv-python-headless 4.5.5.62\n","Uninstalling opencv-python-headless-4.5.5.62:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.62.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-64ac49e1.so.58.91.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-4b79e479.so.58.45.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-805734e8.so.56.51.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-018b8c17.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-ce838cd1.so.15.13.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-6082116c.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-83ce3247.so.3.7.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-7e960168.so.5.7.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-392cd848.so.6.4.0\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n","    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-headless-4.5.5.62\n","Collecting opencv-python-headless==4.1.2.30\n","  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n","\u001b[K     |████████████████████████████████| 21.8 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.19.5)\n","Installing collected packages: opencv-python-headless\n","Successfully installed opencv-python-headless-4.1.2.30\n"]}]},{"cell_type":"code","execution_count":null,"source":["# Chceckpoint is saved every 100 steps\n","\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_config_path} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps} \\\n","    --num_workers=1 \\\n","    --checkpoint_every_n=100 \\\n","    --record_summaries"],"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-17 11:15:34.656164: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0117 11:15:34.659248 139807959418752 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 8000\n","I0117 11:15:34.663217 139807959418752 config_util.py:552] Maybe overwriting train_steps: 8000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0117 11:15:34.663407 139807959418752 config_util.py:552] Maybe overwriting use_bfloat16: False\n","I0117 11:15:34.676234 139807959418752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0117 11:15:34.676352 139807959418752 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0117 11:15:34.676422 139807959418752 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0117 11:15:34.680456 139807959418752 efficientnet_model.py:147] round_filter input=32 output=32\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.697451 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.706861 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.709088 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.709911 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.715583 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.718563 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.724484 139807959418752 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 11:15:34.724590 139807959418752 efficientnet_model.py:147] round_filter input=16 output=16\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.736320 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.737135 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.738584 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.739399 139807959418752 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0117 11:15:34.804022 139807959418752 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 11:15:34.804125 139807959418752 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 11:15:35.017029 139807959418752 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 11:15:35.017170 139807959418752 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 11:15:35.227349 139807959418752 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 11:15:35.227494 139807959418752 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 11:15:35.557813 139807959418752 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 11:15:35.557969 139807959418752 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 11:15:35.879679 139807959418752 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 11:15:35.879846 139807959418752 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 11:15:36.311161 139807959418752 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 11:15:36.311340 139807959418752 efficientnet_model.py:147] round_filter input=320 output=320\n","I0117 11:15:36.424899 139807959418752 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0117 11:15:36.467425 139807959418752 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0117 11:15:36.509695 139807959418752 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/train.record']\n","I0117 11:15:36.524966 139807959418752 dataset_builder.py:163] Reading unweighted datasets: ['/content/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/train.record']\n","I0117 11:15:36.525164 139807959418752 dataset_builder.py:80] Reading record datasets for input file: ['/content/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0117 11:15:36.525279 139807959418752 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0117 11:15:36.525365 139807959418752 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0117 11:15:36.530396 139807959418752 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0117 11:15:36.554539 139807959418752 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0117 11:15:43.630941 139807959418752 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0117 11:15:47.548200 139807959418752 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2022-01-17 11:15:50.959073: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0117 11:16:30.682779 139802662881024 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0117 11:16:39.566487 139802662881024 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0117 11:16:52.206383 139802662881024 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0117 11:17:04.128047 139802662881024 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","W0117 11:17:16.071631 139802662881024 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","INFO:tensorflow:Step 100 per-step time 1.957s\n","I0117 11:19:46.046267 139807959418752 model_lib_v2.py:707] Step 100 per-step time 1.957s\n","INFO:tensorflow:{'Loss/classification_loss': 0.8589904,\n"," 'Loss/localization_loss': 0.4541538,\n"," 'Loss/regularization_loss': 0.028347671,\n"," 'Loss/total_loss': 1.3414918,\n"," 'learning_rate': 0.00416}\n","I0117 11:19:46.046602 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.8589904,\n"," 'Loss/localization_loss': 0.4541538,\n"," 'Loss/regularization_loss': 0.028347671,\n"," 'Loss/total_loss': 1.3414918,\n"," 'learning_rate': 0.00416}\n","INFO:tensorflow:Step 200 per-step time 1.228s\n","I0117 11:21:48.828730 139807959418752 model_lib_v2.py:707] Step 200 per-step time 1.228s\n","INFO:tensorflow:{'Loss/classification_loss': 0.60070413,\n"," 'Loss/localization_loss': 0.2297168,\n"," 'Loss/regularization_loss': 0.028362133,\n"," 'Loss/total_loss': 0.85878307,\n"," 'learning_rate': 0.0073200003}\n","I0117 11:21:48.829059 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.60070413,\n"," 'Loss/localization_loss': 0.2297168,\n"," 'Loss/regularization_loss': 0.028362133,\n"," 'Loss/total_loss': 0.85878307,\n"," 'learning_rate': 0.0073200003}\n","INFO:tensorflow:Step 300 per-step time 1.231s\n","I0117 11:23:51.935563 139807959418752 model_lib_v2.py:707] Step 300 per-step time 1.231s\n","INFO:tensorflow:{'Loss/classification_loss': 0.46171582,\n"," 'Loss/localization_loss': 0.09375877,\n"," 'Loss/regularization_loss': 0.02838372,\n"," 'Loss/total_loss': 0.5838583,\n"," 'learning_rate': 0.010480001}\n","I0117 11:23:51.935873 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.46171582,\n"," 'Loss/localization_loss': 0.09375877,\n"," 'Loss/regularization_loss': 0.02838372,\n"," 'Loss/total_loss': 0.5838583,\n"," 'learning_rate': 0.010480001}\n","INFO:tensorflow:Step 400 per-step time 1.225s\n","I0117 11:25:54.462766 139807959418752 model_lib_v2.py:707] Step 400 per-step time 1.225s\n","INFO:tensorflow:{'Loss/classification_loss': 0.24363549,\n"," 'Loss/localization_loss': 0.072911955,\n"," 'Loss/regularization_loss': 0.028423127,\n"," 'Loss/total_loss': 0.34497055,\n"," 'learning_rate': 0.0136400005}\n","I0117 11:25:54.463101 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.24363549,\n"," 'Loss/localization_loss': 0.072911955,\n"," 'Loss/regularization_loss': 0.028423127,\n"," 'Loss/total_loss': 0.34497055,\n"," 'learning_rate': 0.0136400005}\n","INFO:tensorflow:Step 500 per-step time 1.230s\n","I0117 11:27:57.509800 139807959418752 model_lib_v2.py:707] Step 500 per-step time 1.230s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2359663,\n"," 'Loss/localization_loss': 0.07345553,\n"," 'Loss/regularization_loss': 0.02846505,\n"," 'Loss/total_loss': 0.33788687,\n"," 'learning_rate': 0.016800001}\n","I0117 11:27:57.510113 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.2359663,\n"," 'Loss/localization_loss': 0.07345553,\n"," 'Loss/regularization_loss': 0.02846505,\n"," 'Loss/total_loss': 0.33788687,\n"," 'learning_rate': 0.016800001}\n","INFO:tensorflow:Step 600 per-step time 1.232s\n","I0117 11:30:00.724393 139807959418752 model_lib_v2.py:707] Step 600 per-step time 1.232s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21525799,\n"," 'Loss/localization_loss': 0.054824002,\n"," 'Loss/regularization_loss': 0.028526092,\n"," 'Loss/total_loss': 0.2986081,\n"," 'learning_rate': 0.019960001}\n","I0117 11:30:00.724693 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.21525799,\n"," 'Loss/localization_loss': 0.054824002,\n"," 'Loss/regularization_loss': 0.028526092,\n"," 'Loss/total_loss': 0.2986081,\n"," 'learning_rate': 0.019960001}\n","INFO:tensorflow:Step 700 per-step time 1.230s\n","I0117 11:32:03.760375 139807959418752 model_lib_v2.py:707] Step 700 per-step time 1.230s\n","INFO:tensorflow:{'Loss/classification_loss': 0.19461006,\n"," 'Loss/localization_loss': 0.06479436,\n"," 'Loss/regularization_loss': 0.028617242,\n"," 'Loss/total_loss': 0.28802168,\n"," 'learning_rate': 0.023120001}\n","I0117 11:32:03.760698 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.19461006,\n"," 'Loss/localization_loss': 0.06479436,\n"," 'Loss/regularization_loss': 0.028617242,\n"," 'Loss/total_loss': 0.28802168,\n"," 'learning_rate': 0.023120001}\n","INFO:tensorflow:Step 800 per-step time 1.222s\n","I0117 11:34:05.937568 139807959418752 model_lib_v2.py:707] Step 800 per-step time 1.222s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20619775,\n"," 'Loss/localization_loss': 0.05895589,\n"," 'Loss/regularization_loss': 0.028675152,\n"," 'Loss/total_loss': 0.2938288,\n"," 'learning_rate': 0.02628}\n","I0117 11:34:05.937887 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.20619775,\n"," 'Loss/localization_loss': 0.05895589,\n"," 'Loss/regularization_loss': 0.028675152,\n"," 'Loss/total_loss': 0.2938288,\n"," 'learning_rate': 0.02628}\n","INFO:tensorflow:Step 900 per-step time 1.235s\n","I0117 11:36:09.401260 139807959418752 model_lib_v2.py:707] Step 900 per-step time 1.235s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16225052,\n"," 'Loss/localization_loss': 0.10971581,\n"," 'Loss/regularization_loss': 0.02874945,\n"," 'Loss/total_loss': 0.30071577,\n"," 'learning_rate': 0.02944}\n","I0117 11:36:09.401623 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.16225052,\n"," 'Loss/localization_loss': 0.10971581,\n"," 'Loss/regularization_loss': 0.02874945,\n"," 'Loss/total_loss': 0.30071577,\n"," 'learning_rate': 0.02944}\n","INFO:tensorflow:Step 1000 per-step time 1.249s\n","I0117 11:38:14.273015 139807959418752 model_lib_v2.py:707] Step 1000 per-step time 1.249s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2216719,\n"," 'Loss/localization_loss': 0.04100123,\n"," 'Loss/regularization_loss': 0.028884666,\n"," 'Loss/total_loss': 0.2915578,\n"," 'learning_rate': 0.0326}\n","I0117 11:38:14.273369 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.2216719,\n"," 'Loss/localization_loss': 0.04100123,\n"," 'Loss/regularization_loss': 0.028884666,\n"," 'Loss/total_loss': 0.2915578,\n"," 'learning_rate': 0.0326}\n","INFO:tensorflow:Step 1100 per-step time 1.253s\n","I0117 11:40:19.573427 139807959418752 model_lib_v2.py:707] Step 1100 per-step time 1.253s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15818053,\n"," 'Loss/localization_loss': 0.038405057,\n"," 'Loss/regularization_loss': 0.029048977,\n"," 'Loss/total_loss': 0.22563457,\n"," 'learning_rate': 0.03576}\n","I0117 11:40:19.573760 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.15818053,\n"," 'Loss/localization_loss': 0.038405057,\n"," 'Loss/regularization_loss': 0.029048977,\n"," 'Loss/total_loss': 0.22563457,\n"," 'learning_rate': 0.03576}\n","INFO:tensorflow:Step 1200 per-step time 1.258s\n","I0117 11:42:25.396496 139807959418752 model_lib_v2.py:707] Step 1200 per-step time 1.258s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17270273,\n"," 'Loss/localization_loss': 0.043840393,\n"," 'Loss/regularization_loss': 0.029360577,\n"," 'Loss/total_loss': 0.2459037,\n"," 'learning_rate': 0.03892}\n","I0117 11:42:25.396841 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.17270273,\n"," 'Loss/localization_loss': 0.043840393,\n"," 'Loss/regularization_loss': 0.029360577,\n"," 'Loss/total_loss': 0.2459037,\n"," 'learning_rate': 0.03892}\n","INFO:tensorflow:Step 1300 per-step time 1.252s\n","I0117 11:44:30.579732 139807959418752 model_lib_v2.py:707] Step 1300 per-step time 1.252s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18218753,\n"," 'Loss/localization_loss': 0.047851145,\n"," 'Loss/regularization_loss': 0.029558498,\n"," 'Loss/total_loss': 0.25959718,\n"," 'learning_rate': 0.04208}\n","I0117 11:44:30.580074 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.18218753,\n"," 'Loss/localization_loss': 0.047851145,\n"," 'Loss/regularization_loss': 0.029558498,\n"," 'Loss/total_loss': 0.25959718,\n"," 'learning_rate': 0.04208}\n","INFO:tensorflow:Step 1400 per-step time 1.254s\n","I0117 11:46:35.994000 139807959418752 model_lib_v2.py:707] Step 1400 per-step time 1.254s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13406195,\n"," 'Loss/localization_loss': 0.036315326,\n"," 'Loss/regularization_loss': 0.029725213,\n"," 'Loss/total_loss': 0.20010248,\n"," 'learning_rate': 0.04524}\n","I0117 11:46:35.994321 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.13406195,\n"," 'Loss/localization_loss': 0.036315326,\n"," 'Loss/regularization_loss': 0.029725213,\n"," 'Loss/total_loss': 0.20010248,\n"," 'learning_rate': 0.04524}\n","INFO:tensorflow:Step 1500 per-step time 1.257s\n","I0117 11:48:41.667933 139807959418752 model_lib_v2.py:707] Step 1500 per-step time 1.257s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14370921,\n"," 'Loss/localization_loss': 0.04657374,\n"," 'Loss/regularization_loss': 0.030053325,\n"," 'Loss/total_loss': 0.22033627,\n"," 'learning_rate': 0.0484}\n","I0117 11:48:41.668295 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.14370921,\n"," 'Loss/localization_loss': 0.04657374,\n"," 'Loss/regularization_loss': 0.030053325,\n"," 'Loss/total_loss': 0.22033627,\n"," 'learning_rate': 0.0484}\n","INFO:tensorflow:Step 1600 per-step time 1.260s\n","I0117 11:50:47.672450 139807959418752 model_lib_v2.py:707] Step 1600 per-step time 1.260s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16436163,\n"," 'Loss/localization_loss': 0.062132098,\n"," 'Loss/regularization_loss': 0.030331742,\n"," 'Loss/total_loss': 0.25682548,\n"," 'learning_rate': 0.05156}\n","I0117 11:50:47.672779 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.16436163,\n"," 'Loss/localization_loss': 0.062132098,\n"," 'Loss/regularization_loss': 0.030331742,\n"," 'Loss/total_loss': 0.25682548,\n"," 'learning_rate': 0.05156}\n","INFO:tensorflow:Step 1700 per-step time 1.255s\n","I0117 11:52:53.151689 139807959418752 model_lib_v2.py:707] Step 1700 per-step time 1.255s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14882341,\n"," 'Loss/localization_loss': 0.03555986,\n"," 'Loss/regularization_loss': 0.030518608,\n"," 'Loss/total_loss': 0.21490188,\n"," 'learning_rate': 0.05472}\n","I0117 11:52:53.152016 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.14882341,\n"," 'Loss/localization_loss': 0.03555986,\n"," 'Loss/regularization_loss': 0.030518608,\n"," 'Loss/total_loss': 0.21490188,\n"," 'learning_rate': 0.05472}\n","INFO:tensorflow:Step 1800 per-step time 1.257s\n","I0117 11:54:58.812548 139807959418752 model_lib_v2.py:707] Step 1800 per-step time 1.257s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11698519,\n"," 'Loss/localization_loss': 0.04297331,\n"," 'Loss/regularization_loss': 0.030841144,\n"," 'Loss/total_loss': 0.19079964,\n"," 'learning_rate': 0.05788}\n","I0117 11:54:58.812911 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.11698519,\n"," 'Loss/localization_loss': 0.04297331,\n"," 'Loss/regularization_loss': 0.030841144,\n"," 'Loss/total_loss': 0.19079964,\n"," 'learning_rate': 0.05788}\n","INFO:tensorflow:Step 1900 per-step time 1.247s\n","I0117 11:57:03.507119 139807959418752 model_lib_v2.py:707] Step 1900 per-step time 1.247s\n","INFO:tensorflow:{'Loss/classification_loss': 0.120144114,\n"," 'Loss/localization_loss': 0.03723723,\n"," 'Loss/regularization_loss': 0.031141723,\n"," 'Loss/total_loss': 0.18852307,\n"," 'learning_rate': 0.06104}\n","I0117 11:57:03.507451 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.120144114,\n"," 'Loss/localization_loss': 0.03723723,\n"," 'Loss/regularization_loss': 0.031141723,\n"," 'Loss/total_loss': 0.18852307,\n"," 'learning_rate': 0.06104}\n","INFO:tensorflow:Step 2000 per-step time 1.254s\n","I0117 11:59:08.897914 139807959418752 model_lib_v2.py:707] Step 2000 per-step time 1.254s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13010632,\n"," 'Loss/localization_loss': 0.05045745,\n"," 'Loss/regularization_loss': 0.031427406,\n"," 'Loss/total_loss': 0.21199116,\n"," 'learning_rate': 0.06420001}\n","I0117 11:59:08.898239 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.13010632,\n"," 'Loss/localization_loss': 0.05045745,\n"," 'Loss/regularization_loss': 0.031427406,\n"," 'Loss/total_loss': 0.21199116,\n"," 'learning_rate': 0.06420001}\n","INFO:tensorflow:Step 2100 per-step time 1.254s\n","I0117 12:01:14.326427 139807959418752 model_lib_v2.py:707] Step 2100 per-step time 1.254s\n","INFO:tensorflow:{'Loss/classification_loss': 0.123165086,\n"," 'Loss/localization_loss': 0.036118116,\n"," 'Loss/regularization_loss': 0.03161822,\n"," 'Loss/total_loss': 0.19090143,\n"," 'learning_rate': 0.067360006}\n","I0117 12:01:14.326741 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.123165086,\n"," 'Loss/localization_loss': 0.036118116,\n"," 'Loss/regularization_loss': 0.03161822,\n"," 'Loss/total_loss': 0.19090143,\n"," 'learning_rate': 0.067360006}\n","INFO:tensorflow:Step 2200 per-step time 1.257s\n","I0117 12:03:20.026116 139807959418752 model_lib_v2.py:707] Step 2200 per-step time 1.257s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14805233,\n"," 'Loss/localization_loss': 0.03491336,\n"," 'Loss/regularization_loss': 0.031951338,\n"," 'Loss/total_loss': 0.21491703,\n"," 'learning_rate': 0.070520006}\n","I0117 12:03:20.026432 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.14805233,\n"," 'Loss/localization_loss': 0.03491336,\n"," 'Loss/regularization_loss': 0.031951338,\n"," 'Loss/total_loss': 0.21491703,\n"," 'learning_rate': 0.070520006}\n","INFO:tensorflow:Step 2300 per-step time 1.257s\n","I0117 12:05:25.761981 139807959418752 model_lib_v2.py:707] Step 2300 per-step time 1.257s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15347742,\n"," 'Loss/localization_loss': 0.035830863,\n"," 'Loss/regularization_loss': 0.032580037,\n"," 'Loss/total_loss': 0.2218883,\n"," 'learning_rate': 0.073680006}\n","I0117 12:05:25.762305 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.15347742,\n"," 'Loss/localization_loss': 0.035830863,\n"," 'Loss/regularization_loss': 0.032580037,\n"," 'Loss/total_loss': 0.2218883,\n"," 'learning_rate': 0.073680006}\n","INFO:tensorflow:Step 2400 per-step time 1.257s\n","I0117 12:07:31.437766 139807959418752 model_lib_v2.py:707] Step 2400 per-step time 1.257s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12146583,\n"," 'Loss/localization_loss': 0.027774751,\n"," 'Loss/regularization_loss': 0.03276089,\n"," 'Loss/total_loss': 0.18200147,\n"," 'learning_rate': 0.076840006}\n","I0117 12:07:31.438106 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.12146583,\n"," 'Loss/localization_loss': 0.027774751,\n"," 'Loss/regularization_loss': 0.03276089,\n"," 'Loss/total_loss': 0.18200147,\n"," 'learning_rate': 0.076840006}\n","INFO:tensorflow:Step 2500 per-step time 1.253s\n","I0117 12:09:36.689479 139807959418752 model_lib_v2.py:707] Step 2500 per-step time 1.253s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1186722,\n"," 'Loss/localization_loss': 0.028911807,\n"," 'Loss/regularization_loss': 0.03290662,\n"," 'Loss/total_loss': 0.18049061,\n"," 'learning_rate': 0.08}\n","I0117 12:09:36.689777 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.1186722,\n"," 'Loss/localization_loss': 0.028911807,\n"," 'Loss/regularization_loss': 0.03290662,\n"," 'Loss/total_loss': 0.18049061,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 2600 per-step time 1.257s\n","I0117 12:11:42.409638 139807959418752 model_lib_v2.py:707] Step 2600 per-step time 1.257s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16952397,\n"," 'Loss/localization_loss': 0.046432693,\n"," 'Loss/regularization_loss': 0.033282563,\n"," 'Loss/total_loss': 0.24923922,\n"," 'learning_rate': 0.079999976}\n","I0117 12:11:42.409965 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.16952397,\n"," 'Loss/localization_loss': 0.046432693,\n"," 'Loss/regularization_loss': 0.033282563,\n"," 'Loss/total_loss': 0.24923922,\n"," 'learning_rate': 0.079999976}\n","INFO:tensorflow:Step 2700 per-step time 1.257s\n","I0117 12:13:48.131043 139807959418752 model_lib_v2.py:707] Step 2700 per-step time 1.257s\n","INFO:tensorflow:{'Loss/classification_loss': 0.09143098,\n"," 'Loss/localization_loss': 0.02018648,\n"," 'Loss/regularization_loss': 0.033527818,\n"," 'Loss/total_loss': 0.14514528,\n"," 'learning_rate': 0.07999991}\n","I0117 12:13:48.131395 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.09143098,\n"," 'Loss/localization_loss': 0.02018648,\n"," 'Loss/regularization_loss': 0.033527818,\n"," 'Loss/total_loss': 0.14514528,\n"," 'learning_rate': 0.07999991}\n","INFO:tensorflow:Step 2800 per-step time 1.255s\n","I0117 12:15:53.647316 139807959418752 model_lib_v2.py:707] Step 2800 per-step time 1.255s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12387386,\n"," 'Loss/localization_loss': 0.030020082,\n"," 'Loss/regularization_loss': 0.03362969,\n"," 'Loss/total_loss': 0.18752363,\n"," 'learning_rate': 0.0799998}\n","I0117 12:15:53.647622 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.12387386,\n"," 'Loss/localization_loss': 0.030020082,\n"," 'Loss/regularization_loss': 0.03362969,\n"," 'Loss/total_loss': 0.18752363,\n"," 'learning_rate': 0.0799998}\n","INFO:tensorflow:Step 2900 per-step time 1.255s\n","I0117 12:17:59.163240 139807959418752 model_lib_v2.py:707] Step 2900 per-step time 1.255s\n","INFO:tensorflow:{'Loss/classification_loss': 0.19798124,\n"," 'Loss/localization_loss': 0.055854812,\n"," 'Loss/regularization_loss': 0.03477903,\n"," 'Loss/total_loss': 0.28861508,\n"," 'learning_rate': 0.07999964}\n","I0117 12:17:59.163545 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.19798124,\n"," 'Loss/localization_loss': 0.055854812,\n"," 'Loss/regularization_loss': 0.03477903,\n"," 'Loss/total_loss': 0.28861508,\n"," 'learning_rate': 0.07999964}\n","INFO:tensorflow:Step 3000 per-step time 1.226s\n","I0117 12:20:01.812384 139807959418752 model_lib_v2.py:707] Step 3000 per-step time 1.226s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12652194,\n"," 'Loss/localization_loss': 0.025813628,\n"," 'Loss/regularization_loss': 0.034960315,\n"," 'Loss/total_loss': 0.18729588,\n"," 'learning_rate': 0.07999944}\n","I0117 12:20:01.812696 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.12652194,\n"," 'Loss/localization_loss': 0.025813628,\n"," 'Loss/regularization_loss': 0.034960315,\n"," 'Loss/total_loss': 0.18729588,\n"," 'learning_rate': 0.07999944}\n","INFO:tensorflow:Step 3100 per-step time 1.228s\n","I0117 12:22:04.653490 139807959418752 model_lib_v2.py:707] Step 3100 per-step time 1.228s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13825905,\n"," 'Loss/localization_loss': 0.03933602,\n"," 'Loss/regularization_loss': 0.035175778,\n"," 'Loss/total_loss': 0.21277085,\n"," 'learning_rate': 0.07999919}\n","I0117 12:22:04.653785 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.13825905,\n"," 'Loss/localization_loss': 0.03933602,\n"," 'Loss/regularization_loss': 0.035175778,\n"," 'Loss/total_loss': 0.21277085,\n"," 'learning_rate': 0.07999919}\n","INFO:tensorflow:Step 3200 per-step time 1.229s\n","I0117 12:24:07.512444 139807959418752 model_lib_v2.py:707] Step 3200 per-step time 1.229s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11684978,\n"," 'Loss/localization_loss': 0.030526964,\n"," 'Loss/regularization_loss': 0.0354319,\n"," 'Loss/total_loss': 0.18280864,\n"," 'learning_rate': 0.0799989}\n","I0117 12:24:07.512781 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.11684978,\n"," 'Loss/localization_loss': 0.030526964,\n"," 'Loss/regularization_loss': 0.0354319,\n"," 'Loss/total_loss': 0.18280864,\n"," 'learning_rate': 0.0799989}\n","INFO:tensorflow:Step 3300 per-step time 1.222s\n","I0117 12:26:09.668723 139807959418752 model_lib_v2.py:707] Step 3300 per-step time 1.222s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17673221,\n"," 'Loss/localization_loss': 0.04227084,\n"," 'Loss/regularization_loss': 0.03592608,\n"," 'Loss/total_loss': 0.25492913,\n"," 'learning_rate': 0.07999857}\n","I0117 12:26:09.669032 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.17673221,\n"," 'Loss/localization_loss': 0.04227084,\n"," 'Loss/regularization_loss': 0.03592608,\n"," 'Loss/total_loss': 0.25492913,\n"," 'learning_rate': 0.07999857}\n","INFO:tensorflow:Step 3400 per-step time 1.230s\n","I0117 12:28:12.685245 139807959418752 model_lib_v2.py:707] Step 3400 per-step time 1.230s\n","INFO:tensorflow:{'Loss/classification_loss': 0.088689476,\n"," 'Loss/localization_loss': 0.023625597,\n"," 'Loss/regularization_loss': 0.036183283,\n"," 'Loss/total_loss': 0.14849836,\n"," 'learning_rate': 0.07999819}\n","I0117 12:28:12.685573 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.088689476,\n"," 'Loss/localization_loss': 0.023625597,\n"," 'Loss/regularization_loss': 0.036183283,\n"," 'Loss/total_loss': 0.14849836,\n"," 'learning_rate': 0.07999819}\n","INFO:tensorflow:Step 3500 per-step time 1.231s\n","I0117 12:30:15.752994 139807959418752 model_lib_v2.py:707] Step 3500 per-step time 1.231s\n","INFO:tensorflow:{'Loss/classification_loss': 0.086363636,\n"," 'Loss/localization_loss': 0.017121684,\n"," 'Loss/regularization_loss': 0.03635609,\n"," 'Loss/total_loss': 0.13984141,\n"," 'learning_rate': 0.07999776}\n","I0117 12:30:15.753290 139807959418752 model_lib_v2.py:708] {'Loss/classification_loss': 0.086363636,\n"," 'Loss/localization_loss': 0.017121684,\n"," 'Loss/regularization_loss': 0.03635609,\n"," 'Loss/total_loss': 0.13984141,\n"," 'learning_rate': 0.07999776}\n","^C\n"]}],"metadata":{"id":"t2zxx5AXiNNK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"434eadd6-607d-4d8a-a01c-3fca9c47c69d","executionInfo":{"status":"ok","timestamp":1642422706151,"user_tz":-60,"elapsed":4575277,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["%load_ext tensorboard\n","%tensorboard --logdir '/content/training/eval'"],"outputs":[],"metadata":{"id":"PK8amcT_wgVb"}},{"cell_type":"code","source":["# Error during evaluation\n","\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path='/content/model_config.config' \\\n","    --model_dir='/content/training' \\\n","    --checkpoint_dir='/content/training'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWAYwoQXGnio","executionInfo":{"status":"ok","timestamp":1642434990016,"user_tz":-60,"elapsed":21132,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}},"outputId":"fc26f7a0-ca84-4791-9b55-0b472ab54256"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0117 15:56:13.142971 139952092878720 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I0117 15:56:13.143233 139952092878720 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0117 15:56:13.143353 139952092878720 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0117 15:56:13.143482 139952092878720 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0117 15:56:13.143654 139952092878720 model_lib_v2.py:1111] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2022-01-17 15:56:13.729458: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0117 15:56:13.739016 139952092878720 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0117 15:56:13.739219 139952092878720 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0117 15:56:13.739311 139952092878720 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0117 15:56:13.744313 139952092878720 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:56:13.771145 139952092878720 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 15:56:13.771359 139952092878720 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:56:13.845118 139952092878720 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 15:56:13.845330 139952092878720 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:56:14.032278 139952092878720 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 15:56:14.032506 139952092878720 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 15:56:14.213941 139952092878720 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 15:56:14.214152 139952092878720 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 15:56:14.503315 139952092878720 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 15:56:14.503529 139952092878720 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 15:56:14.786751 139952092878720 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 15:56:14.787002 139952092878720 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 15:56:15.152680 139952092878720 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 15:56:15.152864 139952092878720 efficientnet_model.py:147] round_filter input=320 output=320\n","I0117 15:56:15.240081 139952092878720 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0117 15:56:15.279081 139952092878720 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:Reading unweighted datasets: ['/content/test.record']\n","I0117 15:56:15.332766 139952092878720 dataset_builder.py:163] Reading unweighted datasets: ['/content/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/test.record']\n","I0117 15:56:15.332997 139952092878720 dataset_builder.py:80] Reading record datasets for input file: ['/content/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0117 15:56:15.333179 139952092878720 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0117 15:56:15.333329 139952092878720 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0117 15:56:15.335163 139952092878720 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0117 15:56:15.357187 139952092878720 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0117 15:56:20.587545 139952092878720 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0117 15:56:22.231813 139952092878720 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at /content/training\n","I0117 15:56:25.714590 139952092878720 checkpoint_utils.py:140] Waiting for new checkpoint at /content/training\n","INFO:tensorflow:Found new checkpoint at /content/training/ckpt-36\n","I0117 15:56:25.715691 139952092878720 checkpoint_utils.py:149] Found new checkpoint at /content/training/ckpt-36\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/models/research/object_detection/model_main_tf2.py\", line 90, in main\n","    wait_interval=300, timeout=FLAGS.eval_timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1165, in eval_continuously\n","    global_step=global_step,\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1009, in eager_eval_loop\n","    for evaluator in evaluators:\n","TypeError: 'NoneType' object is not iterable\n"]}]},{"cell_type":"markdown","source":["## Export model inference graph"],"metadata":{"id":"U3GNLS4ywstA"}},{"cell_type":"code","execution_count":null,"source":["output_directory = 'inference_graph'\n","\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir={model_dir} \\\n","    --output_directory={output_directory} \\\n","    --pipeline_config_path={pipeline_config_path}"],"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-17 12:49:47.251371: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0117 12:49:47.260250 139857967970176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0117 12:49:47.260438 139857967970176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0117 12:49:47.260507 139857967970176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0117 12:49:47.264006 139857967970176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 12:49:47.284433 139857967970176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0117 12:49:47.284553 139857967970176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 12:49:47.338689 139857967970176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0117 12:49:47.338803 139857967970176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 12:49:47.476760 139857967970176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0117 12:49:47.476889 139857967970176 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 12:49:47.612279 139857967970176 efficientnet_model.py:147] round_filter input=40 output=40\n","I0117 12:49:47.612420 139857967970176 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 12:49:47.819246 139857967970176 efficientnet_model.py:147] round_filter input=80 output=80\n","I0117 12:49:47.819398 139857967970176 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 12:49:48.137903 139857967970176 efficientnet_model.py:147] round_filter input=112 output=112\n","I0117 12:49:48.138078 139857967970176 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 12:49:48.412173 139857967970176 efficientnet_model.py:147] round_filter input=192 output=192\n","I0117 12:49:48.412355 139857967970176 efficientnet_model.py:147] round_filter input=320 output=320\n","I0117 12:49:48.476007 139857967970176 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0117 12:49:48.504585 139857967970176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0117 12:49:50.441382 139857967970176 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f322659aa90>, because it is not built.\n","W0117 12:50:07.866311 139857967970176 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f322659aa90>, because it is not built.\n","2022-01-17 12:50:29.576379: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","W0117 12:51:02.809784 139857967970176 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 795). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: inference_graph/saved_model/assets\n","I0117 12:51:20.702752 139857967970176 builder_impl.py:784] Assets written to: inference_graph/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to inference_graph/pipeline.config\n","I0117 12:51:22.077304 139857967970176 config_util.py:254] Writing pipeline config file to inference_graph/pipeline.config\n"]}],"metadata":{"id":"WcvbNjcZw2er","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c01f648-4373-4b75-90ec-7b91d1f9a8d5","executionInfo":{"status":"ok","timestamp":1642423885371,"user_tz":-60,"elapsed":101722,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"code","execution_count":null,"source":["from google.colab import files\n","files.download(f'/content/{output_directory}/saved_model/saved_model.pb') "],"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_7d1c5924-aa14-45ff-a4a0-65f6b7bc9fe7\", \"saved_model.pb\", 19260337)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}],"metadata":{"id":"LcWVXuGAxeZ4","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"8215b721-4144-47b5-e0bc-fb54aaeaa82d","executionInfo":{"status":"ok","timestamp":1642423885372,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}}}},{"cell_type":"markdown","source":["## Test trained model on test images\n","\n","based on [Object Detection API Demo](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) and [Inference from saved model tf2 colab](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb)."],"metadata":{"id":"5tGVwzpLxvSv"}},{"cell_type":"code","execution_count":null,"source":["import io\n","import os\n","import scipy.misc\n","import numpy as np\n","import six\n","import time\n","import glob\n","from IPython.display import display\n","\n","from six import BytesIO\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","%matplotlib inline"],"outputs":[],"metadata":{"id":"hp4wlWrhxyJL"}},{"cell_type":"code","execution_count":null,"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path (this can be local or on colossus)\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"outputs":[],"metadata":{"id":"NEaYWo8WyLS2"}},{"cell_type":"code","execution_count":null,"source":["category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)"],"outputs":[],"metadata":{"id":"OxWU7K_oyVwq"}},{"cell_type":"code","execution_count":null,"source":["tf.keras.backend.clear_session()\n","model = tf.saved_model.load(f'/content/{output_directory}/saved_model')"],"outputs":[],"metadata":{"id":"bkMddTneyesG"}},{"cell_type":"code","execution_count":null,"source":["def run_inference_for_single_image(model, image):\n","  image = np.asarray(image)\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis,...]\n","\n","  # Run inference\n","  model_fn = model.signatures['serving_default']\n","  output_dict = model_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(output_dict.pop('num_detections'))\n","  output_dict = {key:value[0, :num_detections].numpy() \n","                 for key,value in output_dict.items()}\n","  output_dict['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","   \n","  # Handle models with masks:\n","  if 'detection_masks' in output_dict:\n","    # Reframe the the bbox mask to the image size.\n","    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","              output_dict['detection_masks'], output_dict['detection_boxes'],\n","               image.shape[0], image.shape[1])      \n","    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                       tf.uint8)\n","    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    \n","  return output_dict"],"outputs":[],"metadata":{"id":"kxAf3XJBzLHq"}},{"cell_type":"code","execution_count":null,"source":["for image_path in glob.glob('microcontroller-detection/test/*.jpg'):\n","  image_np = load_image_into_numpy_array(image_path)\n","  output_dict = run_inference_for_single_image(model, image_np)\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks_reframed', None),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","  display(Image.fromarray(image_np))"],"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"metadata":{"id":"EEX-m3P1yp4y","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1BuT81o8Ou09dkYq_E3UCoGiRD7sP2b7b"},"executionInfo":{"status":"ok","timestamp":1642423929319,"user_tz":-60,"elapsed":11836,"user":{"displayName":"Kamil Synowiec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14977892366511064320"}},"outputId":"598e8030-afa9-4ebf-e5cb-1e85f1419fe2"}}]}